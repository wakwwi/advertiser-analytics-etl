# ğŸ“Š Advertiser Analytics ETL Pipeline  
### End-to-End Data Engineering Project (Python, Pandas, Logging, Validation)

This project builds a **production-style ETL pipeline** that processes raw marketplace data (Olist dataset) and transforms it into **analytics-ready advertiser KPIs**.  
It is structured like a real engineering codebase used at Microsoft Advertising, Amazon Marketplace Analytics, and other retail media platforms.

---

## ğŸš€ Project Summary

This pipeline:

âœ… Loads raw marketplace data (orders, items, customers, products)  
âœ… Cleans & validates the datasets  
âœ… Builds an advertiser-level **fact table**  
âœ… Computes daily & monthly KPIs  
âœ… Enforces data quality with **Pandera schema validation**  
âœ… Logs every stage using a production-style logger  
âœ… Outputs clean CSVs ready for BI dashboards or analytics  

The structure follows real DE standards with a modular **src/** package.

---

## ğŸ§± Tech Stack

- **Python 3.11**
- **Pandas** (data transformation)
- **Pandera** (data validation)
- **Logging** (observability)
- **Pathlib** (file handling)
- **Conda environment** (reproducibility)

---

## ğŸ“ Project Structure

```
ms_ad_analytics_project/
â”‚
â”œâ”€â”€ data/                           # Raw input CSVs (ignored by Git)
â”œâ”€â”€ output/                         # Final KPI outputs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py                  # Extract step
â”‚   â”œâ”€â”€ transform.py                # Clean, merge, build fact table
â”‚   â”œâ”€â”€ validate.py                 # Pandera schemas
â”‚   â”œâ”€â”€ load.py                     # Save outputs
â”‚   â”œâ”€â”€ logger.py                   # Custom logger
â”‚   â”œâ”€â”€ config.py                   # Config + log level
â”‚   â”œâ”€â”€ pipeline.py                 # Main ETL pipeline
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ advertiser_spend_analytics.ipynb # Notebook version
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Pipeline Architecture (ASCII Diagram)

```
Raw CSV Files
    â”‚
    â–¼
[ Extract ]
    â”‚
    â–¼
[ Clean & Normalize Orders ]
    â”‚
    â–¼
[ Build Advertiser Fact Table ]
    â”‚
    â–¼
[ Validate Data (Pandera) ]
    â”‚
    â–¼
[ Compute KPIs ]
  â€¢ Daily KPIs
  â€¢ Monthly KPIs
    â”‚
    â–¼
[ Load Outputs to /output ]
  â€¢ daily_advertiser_kpis.csv
  â€¢ monthly_advertiser_kpis.csv
```

---

## ğŸ“Š KPIs Produced

Each advertiser receives:

| Metric | Description |
|--------|-------------|
| **orders** | Unique order count |
| **lines** | Items sold |
| **revenue** | price + freight (line-level revenue) |
| **customers** | Unique buyers |

Outputs are available at two time grains:

âœ… **Daily KPIs**  
âœ… **Monthly KPIs**

---

## âœ… Fact Table (Advertiser-Level)

Key columns include:

- `advertiser_id` (seller)  
- `order_id`  
- `customer_id`  
- `order_item_id`  
- `order_date`  
- `order_month`  
- `line_revenue`  

This mirrors a real **fact_sales** table used in enterprise analytics.

---

## âš™ï¸ How to Run the Pipeline

### 1. Create & activate environment  
```
conda create -n msad python=3.11 -y
conda activate msad
```

### 2. Install dependencies  
```
pip install pandas pandera pyarrow python-dotenv pytest
```

### 3. Run the pipeline  
```
python -m src.pipeline
```

### 4. Outputs will appear here:  
```
output/daily_advertiser_kpis.csv
output/monthly_advertiser_kpis.csv
```

---

## ğŸ§ª Data Validation with Pandera

The fact table is validated using a schema that checks:

- Column presence  
- Data types  
- Non-negative revenue  
- Valid advertiser/order/customer IDs  
- Monthly format correctness (`YYYY-MM`)  
- No invalid timestamps  

If validation fails, the pipeline exits â€” this matches production behavior.

---

## ğŸ“œ Logging (Production-Style)

Example log:

```
INFO | Starting ETL pipeline...
INFO | Extract completed successfully.
INFO | Fact table validation passed.
INFO | KPI computation complete.
INFO | Load complete. Files saved to /output.
```

---

## ğŸ¯ Why This Project Matters

This project demonstrates skills required for:

- **Data Engineering**  
- **Analytics Engineering**  
- **Business Analytics**  
- **Data Analytics**

Key competencies you demonstrate:

- ETL design  
- Fact table modeling  
- Data cleaning / normalization  
- KPI engineering  
- Validation & error handling  
- Modular Python code  
- Logging & observability  
- Reproducible environments  

---

## ğŸŒ± Future Enhancements (Optional)

- Add incremental loading (watermark-based)  
- Add pytest unit tests  
- Convert transformations to DuckDB or dbt  
- Schedule using Airflow or Prefect  
- Add a Power BI or Tableau dashboard  

---

## ğŸ‘¤ Author  
**Errol Brown**  
Data Engineering / Analytics  
