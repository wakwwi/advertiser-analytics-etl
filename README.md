# üìä Advertiser Analytics ETL Pipeline  
### End-to-End Data Engineering Project (Python, Pandas, Logging, Validation)

This project builds a **production-style ETL pipeline** that processes raw marketplace data (Olist dataset) and transforms it into **analytics-ready advertiser KPIs**.  
It is structured like a real engineering codebase used at Microsoft Advertising, Amazon Marketplace Analytics, and other retail media platforms.

---

## üöÄ Project Summary

This pipeline:

- Loads raw marketplace data (orders, items, customers, products)  
- Cleans & validates the datasets  
- Builds an advertiser-level **fact table**  
- Computes daily & monthly KPIs  
- Enforces data quality with **Pandera schema validation**  
- Logs every ETL stage  
- Outputs clean CSVs ready for BI dashboards or analytics  

The structure follows real DE standards with a modular **src/** package.

---

## üß± Tech Stack

- **Python 3.11**
- **Pandas**  
- **Pandera**  
- **Pathlib**  
- **Logging**  
- **Conda environment**  

---

## üìÅ Project Structure

```
ms_ad_analytics_project/
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Raw input CSVs (ignored by Git)
‚îú‚îÄ‚îÄ output/                         # Final KPI outputs
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ extract.py                  # Extract step
‚îÇ   ‚îú‚îÄ‚îÄ transform.py                # Clean, merge, build fact table
‚îÇ   ‚îú‚îÄ‚îÄ validate.py                 # Pandera schemas
‚îÇ   ‚îú‚îÄ‚îÄ load.py                     # Save outputs
‚îÇ   ‚îú‚îÄ‚îÄ logger.py                   # Custom logger
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Config + log level
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py                 # Main ETL pipeline
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ advertiser_spend_analytics.ipynb
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üèóÔ∏è Pipeline Architecture (Mermaid Diagram)

```mermaid
flowchart TD

    A[Raw CSV Files\norders, items, customers] --> B[Extract\nextract.py]
    B --> C[Clean & Normalize Data\ntransform.py]
    C --> D[Build Advertiser Fact Table\ntransform.py]
    D --> E[Validate with Pandera\nvalidate.py]
    E --> F[Compute KPIs\ndaily + monthly]
    F --> G[Load Outputs\nload.py]
    G --> H[Output Folder\nCSV exports]

    %% Styles (GitHub-safe)
    classDef yellow fill:#f8d568,stroke:#b8860b,stroke-width:2px,color:#000;
    classDef blue fill:#8ec5fc,stroke:#4682b4,stroke-width:2px,color:#000;
    classDef green fill:#b5e8c8,stroke:#2e8b57,stroke-width:2px,color:#000;
    classDef purple fill:#f6d7fa,stroke:#8b3a9e,stroke-width:2px,color:#000;
    classDef red fill:#ffe6e6,stroke:#cc0000,stroke-width:2px,color:#000;
    classDef lightblue fill:#e8e8ff,stroke:#6666cc,stroke-width:2px,color:#000;
    classDef white fill:#ffffff,stroke:#000,color:#000;

    class A yellow
    class B blue
    class C green
    class D purple
    class E red
    class F lightblue
    class G white
    class H white
```
---

## üìä KPIs Produced

Each advertiser receives:

| Metric | Description |
|--------|-------------|
| **orders** | Unique order count |
| **lines** | Items sold |
| **revenue** | price + freight (line-level revenue) |
| **customers** | Unique buyers |

Outputs delivered:

- **Daily KPIs**  
- **Monthly KPIs**  
- **Advertiser-level fact table**

---

## üì¶ Fact Table Schema (Advertiser-Level)

Key fields:

- `advertiser_id`  
- `order_id`  
- `customer_id`  
- `order_item_id`  
- `order_date`  
- `order_month`  
- `line_revenue`  

This mirrors a real **fact_sales** dataset used in enterprise analytics.

---

## ‚öôÔ∏è How to Run the Pipeline

### 1Ô∏è‚É£ Create & activate environment  
```
conda create -n msad python=3.11 -y
conda activate msad
```

### 2Ô∏è‚É£ Install dependencies  
```
pip install pandas pandera pyarrow python-dotenv pytest
```

### 3Ô∏è‚É£ Run the pipeline  
```
python -m src.pipeline
```

### 4Ô∏è‚É£ Outputs will appear in `/output`  
```
output/daily_advertiser_kpis.csv
output/monthly_advertiser_kpis.csv
```

---

## üß™ Data Validation (Pandera)

The pipeline validates:

- Column presence  
- Data types  
- Non-negative revenue  
- Valid IDs  
- Date formatting (`YYYY-MM`)  
- No invalid timestamps  

Validation failures stop the pipeline ‚Äî matching real production behavior.

---

## üìú Logging (Production Workflow)

Example log:

```
INFO | Starting ETL pipeline...
INFO | Extract completed successfully.
INFO | Fact table validation passed.
INFO | KPI computation complete.
INFO | Load complete. Files saved to /output.
```

---

## üéØ Why This Project Matters

This project demonstrates real DE skills:

- ETL design  
- Fact table modeling  
- Data cleaning / normalization  
- KPI engineering  
- Pandera validation  
- Error handling  
- Logging & observability  
- Modular Python project architecture  
- Reproducible environments  

---

## üå± Future Enhancements

- Incremental loading  
- Unit tests (pytest)  
- Use DuckDB or dbt for modeling  
- Schedule with Airflow or Prefect  
- Add a BI dashboard (Power BI / Tableau)  

---

## üë§ Author  
**Errol Brown**  
Data Engineering & Analytics  
